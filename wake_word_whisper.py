import speech_recognition as sr
import os
import wave
import pyaudio
import numpy as np
import time
import subprocess
import requests  # Spring Boot API ìš”ì²­ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import pyttsx3

# ìŒì„± ë…¹ìŒ ì„¤ì •
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024
SILENCE_LIMIT = 2  # ì¹¨ë¬µ ì‹œê°„ì´ 2ì´ˆ ì´ìƒì´ë©´ ë…¹ìŒ ì¢…ë£Œ
THRESHOLD = 2000  # ì†ŒìŒ ê°ì§€ ì„ê³„ê°’

# Whisper ì‹¤í–‰ ë° ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ ê²½ë¡œ
WHISPER_DIR = "./whisper"  # whisper í´ë”ì—ì„œ ì‹¤í–‰
AUDIO_FILE = os.path.join(WHISPER_DIR, "my_audio.wav")
TEXT_FILE = os.path.join(WHISPER_DIR, "my_audio.wav.txt")


def detect_wake_word():
    recognizer = sr.Recognizer()
    mic = sr.Microphone()

    with mic as source:
        print("ğŸ¤ 'ìë¹„ìŠ¤'ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”...")
        recognizer.adjust_for_ambient_noise(source)
        audio = recognizer.listen(source)

    try:
        text = recognizer.recognize_google(audio, language="ko-KR")
        print(f"ğŸ‘‚ ê°ì§€ëœ ìŒì„±: {text}")

        if "ìë¹„ìŠ¤" in text:
            print("âœ… ì›¨ì´í¬ ì›Œë“œ ê°ì§€ë¨! ë…¹ìŒ ì‹œì‘...")
            record_audio()
            process_with_whisper()

    except sr.UnknownValueError:
        print("âŒ ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except sr.RequestError:
        print("âŒ Google API ìš”ì²­ ì‹¤íŒ¨")


def record_audio():
    audio = pyaudio.PyAudio()
    stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE,
                        input=True, frames_per_buffer=CHUNK)

    print("ğŸ™ ë…¹ìŒ ì¤‘... ë§í•˜ì„¸ìš”!")
    frames = []
    recording = True
    silence_counter = 0

    while recording:
        data = stream.read(CHUNK, exception_on_overflow=False)
        audio_data = np.frombuffer(data, dtype=np.int16)

        if np.max(audio_data) > THRESHOLD:  # ì†ŒìŒ ê°ì§€
            frames.append(data)
            silence_counter = 0
        elif len(frames) > 0:
            silence_counter += 1
            if silence_counter > (SILENCE_LIMIT * RATE / CHUNK):  # ì¹¨ë¬µ ê°ì§€
                print("ğŸ›‘ ë…¹ìŒ ì¢…ë£Œ")
                recording = False

    stream.stop_stream()
    stream.close()
    audio.terminate()

    # WAV íŒŒì¼ ì €ì¥ (whisper í´ë” ë‚´ì— ì €ì¥)
    wf = wave.open(AUDIO_FILE, 'wb')
    wf.setnchannels(CHANNELS)
    wf.setsampwidth(audio.get_sample_size(FORMAT))
    wf.setframerate(RATE)
    wf.writeframes(b''.join(frames))
    wf.close()

    print(f"âœ… {AUDIO_FILE} íŒŒì¼ ì €ì¥ ì™„ë£Œ!")



def text_to_speech(text):
    engine = pyttsx3.init()
    engine.say(text)
    engine.runAndWait()

def process_with_whisper():
    print("ğŸ“ Whisper ì‹¤í–‰ ì¤‘...")

    whisper_cmd = f"./whisper/build/bin/whisper-cli -m {WHISPER_DIR}/models/ggml-medium.bin -f {AUDIO_FILE} -l ko --output-txt"
    
    # Whisper ì‹¤í–‰ (Whisperê°€ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°)
    subprocess.run(whisper_cmd, shell=True, check=True)

    # Whisper ë³€í™˜ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
    while not os.path.exists(TEXT_FILE):
        print("â³ Whisper ë³€í™˜ ëŒ€ê¸° ì¤‘...")
        time.sleep(0.5)

    # ë³€í™˜ëœ í…ìŠ¤íŠ¸ ì½ê¸°
    with open(TEXT_FILE, "r") as file:
        user_input = file.read().strip()

    print(f"ğŸ“¨ Whisper ë³€í™˜ ê²°ê³¼: {user_input}")

    # Spring Boot APIë¡œ í…ìŠ¤íŠ¸ ì „ì†¡
    api_url = "http://localhost:8080/api/process-text"
    response = requests.post(api_url, json={"text": user_input})

    if response.status_code == 200:
        ai_response = response.text
        print(f"ğŸ¤– AI ì‘ë‹µ: {ai_response}")
        text_to_speech(ai_response)

        # # AI ì‘ë‹µì„ TTS ë³€í™˜ í›„ ìŒì„± ì¶œë ¥
        # os.system(f'tts --text "{ai_response}" --out_path whisper/output.wav')
        # os.system("afplay whisper/output.wav")  # Macì—ì„œ ìŒì„± ì¶œë ¥
    else:
        print(f"âŒ API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")


if __name__ == "__main__":
    while True:
        detect_wake_word()  # "ìë¹„ìŠ¤" ê°ì§€ ëŒ€ê¸°


# import speech_recognition as sr
# import os
# import wave
# import pyaudio
# import numpy as np
# import time
# import subprocess

# # ìŒì„± ë…¹ìŒ ì„¤ì •
# FORMAT = pyaudio.paInt16
# CHANNELS = 1
# RATE = 16000
# CHUNK = 1024
# SILENCE_LIMIT = 2  # ì¹¨ë¬µ ì‹œê°„ì´ 2ì´ˆ ì´ìƒì´ë©´ ë…¹ìŒ ì¢…ë£Œ
# THRESHOLD = 2000  # ì†ŒìŒ ê°ì§€ ì„ê³„ê°’

# # Whisper ì‹¤í–‰ ë° ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ ê²½ë¡œ
# WHISPER_DIR = "./whisper"  # whisper í´ë”ì—ì„œ ì‹¤í–‰
# AUDIO_FILE = os.path.join(WHISPER_DIR, "my_audio.wav")
# TEXT_FILE = os.path.join(WHISPER_DIR, "my_audio.wav.txt")


# def detect_wake_word():
#     recognizer = sr.Recognizer()
#     mic = sr.Microphone()

#     with mic as source:
#         print("ğŸ¤ 'ìë¹„ìŠ¤'ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”...")
#         recognizer.adjust_for_ambient_noise(source)
#         audio = recognizer.listen(source)

#     try:
#         text = recognizer.recognize_google(audio, language="ko-KR")
#         print(f"ğŸ‘‚ ê°ì§€ëœ ìŒì„±: {text}")

#         if "ìë¹„ìŠ¤" in text:
#             print("âœ… ì›¨ì´í¬ ì›Œë“œ ê°ì§€ë¨! ë…¹ìŒ ì‹œì‘...")
#             record_audio()
#             process_with_whisper()

#     except sr.UnknownValueError:
#         print("âŒ ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
#     except sr.RequestError:
#         print("âŒ Google API ìš”ì²­ ì‹¤íŒ¨")


# def record_audio():
#     audio = pyaudio.PyAudio()
#     stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE,
#                         input=True, frames_per_buffer=CHUNK)

#     print("ğŸ™ ë…¹ìŒ ì¤‘... ë§í•˜ì„¸ìš”!")
#     frames = []
#     recording = True
#     silence_counter = 0

#     while recording:
#         data = stream.read(CHUNK, exception_on_overflow=False)
#         audio_data = np.frombuffer(data, dtype=np.int16)

#         if np.max(audio_data) > THRESHOLD:  # ì†ŒìŒ ê°ì§€
#             frames.append(data)
#             silence_counter = 0
#         elif len(frames) > 0:
#             silence_counter += 1
#             if silence_counter > (SILENCE_LIMIT * RATE / CHUNK):  # ì¹¨ë¬µ ê°ì§€
#                 print("ğŸ›‘ ë…¹ìŒ ì¢…ë£Œ")
#                 recording = False

#     stream.stop_stream()
#     stream.close()
#     audio.terminate()

#     # WAV íŒŒì¼ ì €ì¥ (whisper í´ë” ë‚´ì— ì €ì¥)
#     wf = wave.open(AUDIO_FILE, 'wb')
#     wf.setnchannels(CHANNELS)
#     wf.setsampwidth(audio.get_sample_size(FORMAT))
#     wf.setframerate(RATE)
#     wf.writeframes(b''.join(frames))
#     wf.close()

#     print(f"âœ… {AUDIO_FILE} íŒŒì¼ ì €ì¥ ì™„ë£Œ!")


# def process_with_whisper():
#     print("ğŸ“ Whisper ì‹¤í–‰ ì¤‘...")

#     # Whisper ì‹¤í–‰ (whisper í´ë” ë‚´ì—ì„œ ì‹¤í–‰)
#     whisper_cmd = f"./whisper/build/bin/whisper-cli -m {WHISPER_DIR}/models/ggml-medium.bin -f {AUDIO_FILE} -l ko --output-txt"
    
#     # subprocess.runì„ ì‚¬ìš©í•˜ì—¬ Whisper ì‹¤í–‰ì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
#     subprocess.run(whisper_cmd, shell=True, check=True)

#     # Whisper ë³€í™˜ì´ ì™„ë£Œë  ë•Œê¹Œì§€ íŒŒì¼ì´ ìƒì„±ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼
#     while not os.path.exists(TEXT_FILE):
#         print("â³ Whisper ë³€í™˜ ëŒ€ê¸° ì¤‘...")
#         time.sleep(0.5)  # 0.5ì´ˆ ëŒ€ê¸° í›„ ë‹¤ì‹œ í™•ì¸

#     # ë³€í™˜ëœ í…ìŠ¤íŠ¸ ì½ê¸°
#     with open(TEXT_FILE, "r") as file:
#         user_input = file.read().strip()

#     print(f"ğŸ“¨ Whisper ë³€í™˜ ê²°ê³¼: {user_input}")


# if __name__ == "__main__":
#     while True:
#         detect_wake_word()  # "ìë¹„ìŠ¤" ê°ì§€ ëŒ€ê¸°

